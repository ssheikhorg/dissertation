{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ssheikhorg/dissertation/blob/main/models_evaluations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5VI43eYCEzw"
      },
      "source": [
        "# Install all the packages needed and import them all"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "o6NKXbxIB_C0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3383d75-df0d-4ff6-a96b-1546a2183435"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "downloading uv 0.8.15 x86_64-unknown-linux-gnu\n",
            "no checksums to verify\n",
            "installing to /usr/local/bin\n",
            "  uv\n",
            "  uvx\n",
            "everything's installed!\n",
            "uv 0.8.15\n",
            "Python 3.12.11\n"
          ]
        }
      ],
      "source": [
        "# Install uv in Colab's default environment\n",
        "!curl -LsSf https://astral.sh/uv/install.sh | sh\n",
        "!uv --version\n",
        "\n",
        "# get python version\n",
        "!python --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "wcoXxLJXdwYz"
      },
      "outputs": [],
      "source": [
        "!uv pip install -q -U \\\n",
        "  numpy==2.0.2 \\\n",
        "  scikit-learn==1.5.2 \\\n",
        "  transformers \\\n",
        "  accelerate \\\n",
        "  bitsandbytes \\\n",
        "  pillow \\\n",
        "  sentence-transformers \\\n",
        "  faiss-cpu \\\n",
        "  datasets \\\n",
        "  pandas \\\n",
        "  matplotlib \\\n",
        "  seaborn \\\n",
        "  plotly \\\n",
        "  tqdm \\\n",
        "  openai \\\n",
        "  anthropic \\\n",
        "  boto3 \\\n",
        "  langchain \\\n",
        "  langchain-huggingface \\\n",
        "  huggingface_hub \\\n",
        "  langchain-community \\\n",
        "  transformers_stream_generator"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import libraries and add global variables"
      ],
      "metadata": {
        "id": "TG8k8c6rBtHM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "from google.colab import userdata\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "# Login to Hugging Face with your token\n",
        "login(token=userdata.get('HF_TOKEN'))\n",
        "\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import json\n",
        "import re\n",
        "import glob\n",
        "import base64\n",
        "from tqdm import tqdm\n",
        "from io import BytesIO\n",
        "from datetime import datetime\n",
        "from PIL import Image\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    pipeline,\n",
        "    BitsAndBytesConfig\n",
        ")\n",
        "# Fixed imports for LangChain compatibility\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "\n",
        "# Check GPU availability\n",
        "print(f\"GPU available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "\n",
        "# Configuration\n",
        "TEMPERATURE = 0.3\n",
        "MAX_TOKENS = 1000\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "ENABLE_RAG = True\n",
        "RAG_TOP_K = 3\n",
        "\n",
        "# Medical Test Data\n",
        "MEDICAL_PROMPTS = [\n",
        "    {\n",
        "        \"question\": \"What are the common symptoms of diabetes?\",\n",
        "        \"reference\": \"Common diabetes symptoms include increased thirst, frequent urination, extreme fatigue, blurred vision, and slow healing of cuts or wounds.\",\n",
        "        \"category\": \"endocrinology\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"How does aspirin work in the body?\",\n",
        "        \"reference\": \"Aspirin works by inhibiting cyclooxygenase enzymes, reducing the production of prostaglandins that cause pain, inflammation, and fever. It also has antiplatelet effects.\",\n",
        "        \"category\": \"pharmacology\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"What is hypertension and what are its risk factors?\",\n",
        "        \"reference\": \"Hypertension, or high blood pressure, is a condition where the force of blood against artery walls is too high. Risk factors include age, family history, obesity, lack of exercise, tobacco use, high sodium diet, and stress.\",\n",
        "        \"category\": \"cardiology\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"What are the main functions of the liver?\",\n",
        "        \"reference\": \"The liver performs several vital functions including detoxification of chemicals, protein synthesis, production of biochemicals necessary for digestion, glycogen storage, and decomposition of red blood cells.\",\n",
        "        \"category\": \"gastroenterology\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"What are the common symptoms of COVID-19?\",\n",
        "        \"reference\": \"Common COVID-19 symptoms include fever, cough, shortness of breath, fatigue, muscle aches, loss of taste or smell, sore throat, and headache.\",\n",
        "        \"category\": \"infectious_disease\"\n",
        "    }\n",
        "]\n",
        "\n",
        "MEDICAL_DATASETS = {\n",
        "    \"pubmedqa\": [\n",
        "        {\n",
        "            \"question\": \"What is the first-line treatment for hypertension?\",\n",
        "            \"reference\": \"First-line treatments for hypertension include thiazide diuretics, ACE inhibitors, angiotensin II receptor blockers, and calcium channel blockers.\",\n",
        "            \"category\": \"cardiology\",\n",
        "            \"dataset\": \"pubmedqa\"\n",
        "        },\n",
        "        {\n",
        "            \"question\": \"How does metformin work in type 2 diabetes?\",\n",
        "            \"reference\": \"Metformin decreases hepatic glucose production, reduces intestinal glucose absorption, and improves insulin sensitivity.\",\n",
        "            \"category\": \"endocrinology\",\n",
        "            \"dataset\": \"pubmedqa\"\n",
        "        }\n",
        "    ],\n",
        "    \"medqa\": [\n",
        "        {\n",
        "            \"question\": \"A 45-year-old patient presents with chest pain radiating to the left arm. What is the most likely diagnosis?\",\n",
        "            \"reference\": \"Chest pain radiating to the left arm is characteristic of myocardial infarction and requires immediate cardiac evaluation.\",\n",
        "            \"category\": \"cardiology\",\n",
        "            \"dataset\": \"medqa\"\n",
        "        },\n",
        "        {\n",
        "            \"question\": \"What is the gold standard test for diagnosing pulmonary embolism?\",\n",
        "            \"reference\": \"CT pulmonary angiography is the gold standard for diagnosing pulmonary embolism.\",\n",
        "            \"category\": \"pulmonology\",\n",
        "            \"dataset\": \"medqa\"\n",
        "        }\n",
        "    ],\n",
        "    \"mimic_cxr\": [\n",
        "        {\n",
        "            \"question\": \"Describe the findings in a chest X-ray showing cardiomegaly and pulmonary edema.\",\n",
        "            \"reference\": \"Cardiomegaly appears as an enlarged cardiac silhouette, while pulmonary edema manifests as bilateral interstitial opacities and Kerley B lines.\",\n",
        "            \"category\": \"radiology\",\n",
        "            \"dataset\": \"mimic_cxr\"\n",
        "        },\n",
        "        {\n",
        "            \"question\": \"What radiographic signs suggest pneumothorax?\",\n",
        "            \"reference\": \"Pneumothorax is characterized by a visible visceral pleural edge, absence of lung markings peripheral to this edge, and possible mediastinal shift.\",\n",
        "            \"category\": \"radiology\",\n",
        "            \"dataset\": \"mimic_cxr\"\n",
        "        }\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Medical knowledge base for fact checking\n",
        "MEDICAL_KNOWLEDGE_BASE = {\n",
        "    \"diabetes\": [\"increased thirst\", \"frequent urination\", \"fatigue\", \"blurred vision\", \"slow healing\", \"metformin\", \"insulin\"],\n",
        "    \"aspirin\": [\"pain relief\", \"anti-inflammatory\", \"blood thinner\", \"fever reducer\", \"inhibit cyclooxygenase\", \"myocardial infarction\"],\n",
        "    \"hypertension\": [\"high blood pressure\", \"silent killer\", \"cardiovascular risk\", \"artery damage\", \"ACE inhibitors\", \"beta blockers\"],\n",
        "    \"liver\": [\"detoxification\", \"protein synthesis\", \"bile production\", \"glycogen storage\", \"jaundice\", \"cirrhosis\"],\n",
        "    \"covid\": [\"fever\", \"cough\", \"shortness of breath\", \"loss of taste/smell\", \"coronavirus\", \"pandemic\"],\n",
        "    \"cardiology\": [\"myocardial infarction\", \"angina\", \"arrhythmia\", \"ECG\", \"troponin\", \"stent\"],\n",
        "    \"pulmonology\": [\"asthma\", \"COPD\", \"pneumonia\", \"spirometry\", \"bronchodilator\", \"oxygen therapy\"],\n",
        "    \"radiology\": [\"x-ray\", \"CT scan\", \"MRI\", \"ultrasound\", \"contrast\", \"radiation\"]\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfw-53lCBerp",
        "outputId": "890dedb6-ea7d-415a-d252-9d0b6aadff8e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU available: True\n",
            "GPU: NVIDIA A100-SXM4-40GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Configuration Functions"
      ],
      "metadata": {
        "id": "92SSTtj3B1CX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model_configs():\n",
        "    \"\"\"Return model configurations with their HuggingFace IDs and quantization requirements\"\"\"\n",
        "    return {\n",
        "        \"llama-2-7b\": {\n",
        "            \"model_id\": \"meta-llama/Llama-2-7b-chat-hf\",\n",
        "            \"requires_special_handling\": False,\n",
        "            \"quantization_support\": True\n",
        "        },\n",
        "        \"mistral-7b\": {\n",
        "            \"model_id\": \"mistralai/Mistral-7B-v0.1\",\n",
        "            \"requires_special_handling\": False,\n",
        "            \"quantization_support\": True\n",
        "        },\n",
        "        \"qwen-7b\": {\n",
        "            \"model_id\": \"Qwen/Qwen2.5-7B-Instruct\",\n",
        "            \"requires_special_handling\": True,\n",
        "            \"quantization_support\": True,\n",
        "            \"padding_side\": \"left\",\n",
        "            \"trust_remote_code\": True\n",
        "        },\n",
        "        \"meditron-7b\": {\n",
        "            \"model_id\": \"epfl-llm/meditron-7b\",\n",
        "            \"requires_special_handling\": False,\n",
        "            \"quantization_support\": True\n",
        "        },\n",
        "        \"biomedgpt\": {\n",
        "            \"model_id\": \"stanford-crfm/BioMedLM\",\n",
        "            \"requires_special_handling\": False,\n",
        "            \"quantization_support\": True\n",
        "        },\n",
        "        \"gpt-oss-20b\": {\n",
        "            \"model_id\": \"openai/gpt-oss-20b\",\n",
        "            \"requires_special_handling\": True,\n",
        "            \"quantization_support\": False,  # This model uses different quantization\n",
        "            \"trust_remote_code\": True\n",
        "        },\n",
        "        \"claude-3.7-sonnet\": {\n",
        "            \"model_id\": \"reedmayhew/claude-3.7-sonnet-reasoning-gemma3-12B\",\n",
        "            \"requires_special_handling\": True,\n",
        "            \"quantization_support\": True,\n",
        "            \"trust_remote_code\": True\n",
        "        },\n",
        "        \"grok-2\": {\n",
        "            \"model_id\": \"xai-org/grok-2\",\n",
        "            \"requires_special_handling\": True,\n",
        "            \"quantization_support\": True,\n",
        "            \"trust_remote_code\": True\n",
        "        }\n",
        "    }\n",
        "\n",
        "\n",
        "def load_local_model(model_name, **kwargs):\n",
        "    \"\"\"Load a local model with pattern matching and proper error handling\"\"\"\n",
        "    model_configs = get_model_configs()\n",
        "\n",
        "    if model_name not in model_configs:\n",
        "        raise ValueError(f\"Model {model_name} not supported\")\n",
        "\n",
        "    config = model_configs[model_name]\n",
        "    model_id = config[\"model_id\"]\n",
        "\n",
        "    try:\n",
        "        # Common tokenizer parameters\n",
        "        tokenizer_kwargs = {\n",
        "            \"use_fast\": True,\n",
        "            \"trust_remote_code\": config.get(\"trust_remote_code\", False)\n",
        "        }\n",
        "\n",
        "        # Load tokenizer\n",
        "        tokenizer = AutoTokenizer.from_pretrained(model_id, **tokenizer_kwargs)\n",
        "\n",
        "        # Handle different model types with pattern matching\n",
        "        if \"qwen\" in model_name.lower():\n",
        "            # Qwen specific handling\n",
        "            if tokenizer.pad_token is None:\n",
        "                tokenizer.pad_token = tokenizer.eos_token\n",
        "            if tokenizer.pad_token_id is None:\n",
        "                tokenizer.pad_token_id = tokenizer.eos_token_id\n",
        "            tokenizer.padding_side = config.get(\"padding_side\", \"left\")\n",
        "\n",
        "        elif \"gpt-oss\" in model_name.lower():\n",
        "            # GPT-OSS-20B specific handling - this model uses different quantization\n",
        "            # Don't use BitsAndBytesConfig for this model\n",
        "            quantization_config = None\n",
        "\n",
        "        elif \"claude\" in model_name.lower():\n",
        "            # Claude model handling\n",
        "            if tokenizer.pad_token is None:\n",
        "                tokenizer.pad_token = tokenizer.eos_token\n",
        "            if tokenizer.pad_token_id is None:\n",
        "                tokenizer.pad_token_id = tokenizer.eos_token_id\n",
        "\n",
        "        else:\n",
        "            # Default handling for other models\n",
        "            if tokenizer.pad_token is None:\n",
        "                tokenizer.pad_token = tokenizer.eos_token\n",
        "            if tokenizer.pad_token_id is None:\n",
        "                tokenizer.pad_token_id = tokenizer.eos_token_id\n",
        "\n",
        "        # Handle quantization configuration\n",
        "        if config[\"quantization_support\"] and torch.cuda.is_available() and \"gpt-oss\" not in model_name.lower():\n",
        "            quantization_config = BitsAndBytesConfig(\n",
        "                load_in_4bit=True,\n",
        "                bnb_4bit_compute_dtype=torch.float16,\n",
        "                bnb_4bit_use_double_quant=True,\n",
        "                bnb_4bit_quant_type=\"nf4\"\n",
        "            )\n",
        "        else:\n",
        "            quantization_config = None\n",
        "\n",
        "        # Model loading parameters\n",
        "        model_kwargs = {\n",
        "            \"device_map\": \"auto\" if torch.cuda.is_available() else None,\n",
        "            \"dtype\": torch.float16 if torch.cuda.is_available() else torch.float32,\n",
        "            \"trust_remote_code\": config.get(\"trust_remote_code\", False),\n",
        "            \"low_cpu_mem_usage\": True,\n",
        "        }\n",
        "\n",
        "        # Add quantization config if applicable\n",
        "        if quantization_config:\n",
        "            model_kwargs[\"quantization_config\"] = quantization_config\n",
        "\n",
        "        # Load model\n",
        "        model = AutoModelForCausalLM.from_pretrained(model_id, **model_kwargs)\n",
        "\n",
        "        # Post-processing for specific models\n",
        "        if \"qwen\" in model_name.lower():\n",
        "            model.config.pad_token_id = tokenizer.pad_token_id\n",
        "            if hasattr(model, 'transformer'):\n",
        "                model.transformer.padding_idx = tokenizer.pad_token_id\n",
        "\n",
        "        # Generation parameters\n",
        "        generation_kwargs = {\n",
        "            \"max_new_tokens\": kwargs.get(\"max_new_tokens\", 384),\n",
        "            \"temperature\": kwargs.get(\"temperature\", TEMPERATURE),\n",
        "            \"do_sample\": kwargs.get(\"do_sample\", True),\n",
        "            \"truncation\": kwargs.get(\"truncation\", True),\n",
        "        }\n",
        "\n",
        "        # Add token IDs if available\n",
        "        if hasattr(tokenizer, 'pad_token_id') and tokenizer.pad_token_id is not None:\n",
        "            generation_kwargs[\"pad_token_id\"] = tokenizer.pad_token_id\n",
        "        if hasattr(tokenizer, 'eos_token_id') and tokenizer.eos_token_id is not None:\n",
        "            generation_kwargs[\"eos_token_id\"] = tokenizer.eos_token_id\n",
        "\n",
        "        # Create pipeline\n",
        "        pipe = pipeline(\n",
        "            \"text-generation\",\n",
        "            model=model,\n",
        "            tokenizer=tokenizer,\n",
        "            **generation_kwargs\n",
        "        )\n",
        "\n",
        "        print(f\"Successfully loaded {model_name}\")\n",
        "        return pipe\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading {model_name}: {str(e)}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "        # Return fallback function\n",
        "        def fallback_pipeline(prompt, **kwargs):\n",
        "            return [{'generated_text': f\"Model {model_name} could not be loaded: {str(e)}\"}]\n",
        "        return fallback_pipeline\n",
        "\n",
        "\n",
        "def load_model_by_category(model_name):\n",
        "    \"\"\"Load model based on its category\"\"\"\n",
        "    categories = get_model_categories()\n",
        "\n",
        "    if model_name in categories[\"local_models\"]:\n",
        "        return load_local_model(model_name)\n",
        "    else:\n",
        "        raise ValueError(f\"Model {model_name} not found in any category\")\n",
        "\n",
        "# Model category handlers using pattern matching\n",
        "MODEL_HANDLERS = {\n",
        "    \"qwen\": {\n",
        "        \"tokenizer_config\": {\n",
        "            \"padding_side\": \"left\",\n",
        "            \"trust_remote_code\": True\n",
        "        },\n",
        "        \"post_processing\": lambda model, tokenizer: setattr(model.config, 'pad_token_id', tokenizer.pad_token_id)\n",
        "    },\n",
        "    \"default\": {\n",
        "        \"quantization\": True,\n",
        "        \"trust_remote_code\": False\n",
        "    }\n",
        "}\n",
        "\n",
        "def get_model_handler(model_name):\n",
        "    \"\"\"Get the appropriate handler for a model based on pattern matching\"\"\"\n",
        "    model_name_lower = model_name.lower()\n",
        "\n",
        "    for pattern, handler in MODEL_HANDLERS.items():\n",
        "        if pattern in model_name_lower and pattern not in [\"gpt-oss\", \"claude\", \"grok\"]:\n",
        "            return handler\n",
        "\n",
        "    return MODEL_HANDLERS[\"default\"]"
      ],
      "metadata": {
        "id": "NDh26IASBoOM"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RAG Functions"
      ],
      "metadata": {
        "id": "i_8vK4YxB9RV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_medical_retriever():\n",
        "    \"\"\"Create a medical knowledge retriever for RAG\"\"\"\n",
        "    medical_knowledge = [\n",
        "        \"Diabetes symptoms include increased thirst, frequent urination, fatigue, blurred vision.\",\n",
        "        \"Aspirin is a nonsteroidal anti-inflammatory drug that reduces pain and inflammation.\",\n",
        "        \"Hypertension (high blood pressure) is a condition where blood pressure is consistently too high.\",\n",
        "        \"The liver performs detoxification, protein synthesis, and produces biochemicals for digestion.\",\n",
        "        \"COVID-19 symptoms include fever, cough, shortness of breath, fatigue, and loss of taste/smell.\",\n",
        "        \"Antibiotics treat bacterial infections but are ineffective against viral infections.\",\n",
        "        \"Vaccines stimulate the immune system to produce antibodies against specific diseases.\",\n",
        "        \"Cancer treatments include surgery, chemotherapy, radiation therapy, and immunotherapy.\",\n",
        "        \"Heart disease risk factors include high blood pressure, high cholesterol, smoking, and diabetes.\",\n",
        "        \"Mental health conditions like depression can be treated with therapy and medication.\"\n",
        "    ]\n",
        "\n",
        "    text_splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=500, chunk_overlap=50\n",
        "    )\n",
        "    documents = text_splitter.create_documents(medical_knowledge)\n",
        "    embeddings = HuggingFaceEmbeddings(\n",
        "        model_name=\"sentence-transformers/all-mpnet-base-v2\"\n",
        "    )\n",
        "\n",
        "    vectorstore = FAISS.from_documents(documents, embeddings)\n",
        "    return vectorstore"
      ],
      "metadata": {
        "id": "ywBGHw3dB7Qc"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Response Generation Functions"
      ],
      "metadata": {
        "id": "R-BsYLrECHi4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_response_local(model, prompt, use_rag=True):\n",
        "    \"\"\"Generate response using local model with error handling\"\"\"\n",
        "    try:\n",
        "        if use_rag:\n",
        "            vectorstore = create_medical_retriever()\n",
        "            docs = vectorstore.similarity_search(prompt, k=RAG_TOP_K)\n",
        "            context = \"\\n\".join([doc.page_content for doc in docs])\n",
        "\n",
        "            prompt_template = \"\"\"You are a medical AI assistant. Use the following medical context to answer the question accurately and factually.\n",
        "            If you don't know the answer based on the context, say you don't know. Be concise and avoid speculation.\n",
        "\n",
        "            Medical Context:\n",
        "            {context}\n",
        "\n",
        "            Question: {question}\n",
        "\n",
        "            Answer:\"\"\"\n",
        "\n",
        "            formatted_prompt = prompt_template.format(context=context, question=prompt)\n",
        "        else:\n",
        "            formatted_prompt = prompt\n",
        "\n",
        "        # Clear memory before generation\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "        # Generate response with proper error handling\n",
        "        try:\n",
        "            # Try the standard approach first\n",
        "            generation_args = {\n",
        "                'max_new_tokens': 384,\n",
        "                'do_sample': True,\n",
        "                'temperature': TEMPERATURE,\n",
        "                'truncation': True,\n",
        "            }\n",
        "\n",
        "            # Add padding token ID if available\n",
        "            if hasattr(model, 'tokenizer') and hasattr(model.tokenizer, 'pad_token_id'):\n",
        "                generation_args['pad_token_id'] = model.tokenizer.pad_token_id\n",
        "\n",
        "            response = model(formatted_prompt, **generation_args)[0]['generated_text']\n",
        "\n",
        "        except Exception as gen_error:\n",
        "            print(f\"Generation error: {str(gen_error)}\")\n",
        "            # Try alternative approach without padding\n",
        "            try:\n",
        "                response = model(\n",
        "                    formatted_prompt,\n",
        "                    max_length=512,\n",
        "                    do_sample=True,\n",
        "                    temperature=TEMPERATURE,\n",
        "                    truncation=True\n",
        "                )[0]['generated_text']\n",
        "            except Exception as alt_error:\n",
        "                print(f\"Alternative generation also failed: {str(alt_error)}\")\n",
        "                return f\"Error in text generation: {str(alt_error)}\"\n",
        "\n",
        "        # Extract answer if using RAG\n",
        "        if use_rag and \"Answer:\" in response:\n",
        "            response = response.split(\"Answer:\")[-1].strip()\n",
        "\n",
        "        # Clear memory after generation\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "        return response.strip()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in generation: {str(e)}\")\n",
        "        # Try to recover memory\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "        return f\"Error generating response: {str(e)}\"\n",
        "\n",
        "def generate_response(model, prompt, use_rag=True, model_name=\"\"):\n",
        "    \"\"\"Generate response using local model only\"\"\"\n",
        "    return generate_response_local(model, prompt, use_rag)"
      ],
      "metadata": {
        "id": "SaRZF1cxCF7r"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation Functions"
      ],
      "metadata": {
        "id": "EgOzhDeHCMz4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_semantic_similarity(reference, response):\n",
        "    \"\"\"Calculate semantic similarity between reference and response\"\"\"\n",
        "    try:\n",
        "        vectorizer = TfidfVectorizer(stop_words='english')\n",
        "        tfidf_matrix = vectorizer.fit_transform([reference, response])\n",
        "        similarity = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])[0][0]\n",
        "        return max(similarity, 0)\n",
        "    except:\n",
        "        return 0.5\n",
        "\n",
        "def check_factual_consistency(response, category):\n",
        "    \"\"\"Check factual consistency with medical knowledge base\"\"\"\n",
        "    if category not in MEDICAL_KNOWLEDGE_BASE:\n",
        "        return 0.7\n",
        "\n",
        "    relevant_facts = MEDICAL_KNOWLEDGE_BASE[category]\n",
        "    response_lower = response.lower()\n",
        "\n",
        "    fact_matches = sum(1 for fact in relevant_facts if fact in response_lower)\n",
        "\n",
        "    if not relevant_facts:\n",
        "        return 0.5\n",
        "\n",
        "    coverage = fact_matches / len(relevant_facts)\n",
        "\n",
        "    contradictions = check_contradictions(response_lower, category)\n",
        "\n",
        "    final_score = coverage * (1 - 0.5 * contradictions)\n",
        "\n",
        "    return max(min(final_score, 1.0), 0.0)\n",
        "\n",
        "def check_contradictions(response, category):\n",
        "    \"\"\"Check for contradictions with known medical facts\"\"\"\n",
        "    contradiction_patterns = {\n",
        "        \"diabetes\": [r\"diabetes.*curable\", r\"diabetes.*not serious\", r\"insulin.*addictive\"],\n",
        "        \"aspirin\": [r\"aspirin.*safe for everyone\", r\"aspirin.*no side effects\", r\"aspirin.*cures\"],\n",
        "        \"covid\": [r\"covid.*just flu\", r\"vaccines.*dangerous\", r\"masks.*don't work\"],\n",
        "        \"cancer\": [r\"cancer.*always fatal\", r\"alternative.*cures cancer\", r\"chemotherapy.*poison\"]\n",
        "    }\n",
        "\n",
        "    if category not in contradiction_patterns:\n",
        "        return 0.0\n",
        "\n",
        "    patterns = contradiction_patterns[category]\n",
        "    contradiction_count = sum(1 for pattern in patterns if re.search(pattern, response))\n",
        "\n",
        "    return min(contradiction_count / len(patterns), 1.0) if patterns else 0.0\n",
        "\n",
        "def pattern_based_hallucination_detection(response):\n",
        "    \"\"\"Fallback hallucination detection using patterns\"\"\"\n",
        "    score = 0.0\n",
        "    response_lower = response.lower()\n",
        "\n",
        "    uncertainty_patterns = [\n",
        "        r\"\\b(I think|I believe|probably|maybe|perhaps|likely)\\b\",\n",
        "        r\"\\b(studies show|research indicates|experts say)\\b\",\n",
        "    ]\n",
        "\n",
        "    for pattern in uncertainty_patterns:\n",
        "        matches = re.findall(pattern, response_lower)\n",
        "        score += len(matches) * 0.1\n",
        "\n",
        "    overgeneralizations = re.findall(r\"\\b(always|never|every|all|none)\\b\", response_lower)\n",
        "    score += len(overgeneralizations) * 0.15\n",
        "\n",
        "    sensational_claims = re.findall(r\"\\b(cure|miracle|breakthrough|revolutionary)\\b\", response_lower)\n",
        "    score += len(sensational_claims) * 0.2\n",
        "\n",
        "    return min(score, 1.0)\n",
        "\n",
        "def calculate_confidence(response):\n",
        "    \"\"\"Calculate confidence score based on response characteristics\"\"\"\n",
        "    confidence = 1.0\n",
        "    response_lower = response.lower()\n",
        "\n",
        "    uncertainty_markers = [\"maybe\", \"perhaps\", \"I think\", \"I believe\", \"probably\"]\n",
        "    for marker in uncertainty_markers:\n",
        "        if marker in response_lower:\n",
        "            confidence -= 0.1\n",
        "\n",
        "    if len(response.split()) < 5:\n",
        "        confidence -= 0.2\n",
        "\n",
        "    return max(confidence, 0.1)\n",
        "\n",
        "def evaluate_hallucination(reference, response, category):\n",
        "    \"\"\"Evaluate hallucination using multiple methods\"\"\"\n",
        "    similarity_score = calculate_semantic_similarity(reference, response)\n",
        "\n",
        "    factual_score = check_factual_consistency(response, category)\n",
        "\n",
        "    pattern_score = pattern_based_hallucination_detection(response)\n",
        "\n",
        "    hallucination_score = 0.4 * (1 - similarity_score) + 0.4 * (1 - factual_score) + 0.2 * pattern_score\n",
        "\n",
        "    return min(hallucination_score, 1.0)\n",
        "\n",
        "def load_test_prompts(sample_count=3, dataset_name=\"all\"):\n",
        "    \"\"\"Load test prompts for evaluation from specified datasets - IMPROVED\"\"\"\n",
        "    prompts = []\n",
        "\n",
        "    if dataset_name == \"all\":\n",
        "        # Sample from ALL medical datasets\n",
        "        for dataset_key, dataset_prompts in MEDICAL_DATASETS.items():\n",
        "            samples_to_take = min(sample_count, len(dataset_prompts))\n",
        "            for i, prompt_data in enumerate(dataset_prompts[:samples_to_take]):\n",
        "                prompts.append({\n",
        "                    \"original_prompt\": prompt_data[\"question\"],\n",
        "                    \"clean_prompt\": prompt_data[\"question\"],\n",
        "                    \"original_reference\": prompt_data[\"reference\"],\n",
        "                    \"clean_reference\": prompt_data[\"reference\"],\n",
        "                    \"category\": prompt_data[\"category\"],\n",
        "                    \"dataset\": prompt_data[\"dataset\"]\n",
        "                })\n",
        "        # Also include some basic medical prompts\n",
        "        medical_samples = min(sample_count, len(MEDICAL_PROMPTS))\n",
        "        for i, prompt_data in enumerate(MEDICAL_PROMPTS[:medical_samples]):\n",
        "            prompts.append({\n",
        "                \"original_prompt\": prompt_data[\"question\"],\n",
        "                \"clean_prompt\": prompt_data[\"question\"],\n",
        "                \"original_reference\": prompt_data[\"reference\"],\n",
        "                \"clean_reference\": prompt_data[\"reference\"],\n",
        "                \"category\": prompt_data[\"category\"],\n",
        "                \"dataset\": \"medical_qa\"\n",
        "            })\n",
        "    elif dataset_name in MEDICAL_DATASETS:\n",
        "        # Sample from specific medical dataset\n",
        "        dataset_prompts = MEDICAL_DATASETS[dataset_name]\n",
        "        samples_to_take = min(sample_count, len(dataset_prompts))\n",
        "        for i, prompt_data in enumerate(dataset_prompts[:samples_to_take]):\n",
        "            prompts.append({\n",
        "                \"original_prompt\": prompt_data[\"question\"],\n",
        "                \"clean_prompt\": prompt_data[\"question\"],\n",
        "                \"original_reference\": prompt_data[\"reference\"],\n",
        "                \"clean_reference\": prompt_data[\"reference\"],\n",
        "                \"category\": prompt_data[\"category\"],\n",
        "                \"dataset\": prompt_data[\"dataset\"]\n",
        "            })\n",
        "    else:\n",
        "        # Fallback to original medical prompts\n",
        "        samples_to_take = min(sample_count, len(MEDICAL_PROMPTS))\n",
        "        for i, prompt_data in enumerate(MEDICAL_PROMPTS[:samples_to_take]):\n",
        "            prompts.append({\n",
        "                \"original_prompt\": prompt_data[\"question\"],\n",
        "                \"clean_prompt\": prompt_data[\"question\"],\n",
        "                \"original_reference\": prompt_data[\"reference\"],\n",
        "                \"clean_reference\": prompt_data[\"reference\"],\n",
        "                \"category\": prompt_data[\"category\"],\n",
        "                \"dataset\": \"medical_qa\"\n",
        "            })\n",
        "\n",
        "    return prompts\n",
        "\n",
        "def evaluate_model_responses(model, prompts, model_name, dataset=\"medical_qa\"):\n",
        "    \"\"\"Evaluate model responses for hallucinations with better error handling\"\"\"\n",
        "    results = {\n",
        "        \"model\": model_name,\n",
        "        \"dataset\": dataset,\n",
        "        \"sample_count\": len(prompts),\n",
        "        \"metrics\": {},\n",
        "        \"dataset_metrics\": {},\n",
        "        \"sample_responses\": []\n",
        "    }\n",
        "\n",
        "    hallucination_scores = []\n",
        "    accuracy_scores = []\n",
        "    confidence_scores = []\n",
        "\n",
        "    for prompt in tqdm(prompts, desc=f\"Evaluating {model_name}\"):\n",
        "        try:\n",
        "            response = generate_response(model, prompt[\"clean_prompt\"], use_rag=ENABLE_RAG, model_name=model_name)\n",
        "\n",
        "            if response.startswith(\"Error:\"):\n",
        "                accuracy = 0.0\n",
        "                hallucination_score = 0.5\n",
        "                confidence = 0.1\n",
        "            else:\n",
        "                accuracy = calculate_semantic_similarity(prompt[\"clean_reference\"], response)\n",
        "                hallucination_score = evaluate_hallucination(prompt[\"clean_reference\"], response, prompt[\"category\"])\n",
        "                confidence = calculate_confidence(response)\n",
        "        except Exception as e:\n",
        "            print(f\"Error evaluating prompt: {str(e)}\")\n",
        "            response = f\"Error: {str(e)}\"\n",
        "            accuracy = 0.0\n",
        "            hallucination_score = 0.5\n",
        "            confidence = 0.1\n",
        "\n",
        "        accuracy_scores.append(accuracy)\n",
        "        hallucination_scores.append(hallucination_score)\n",
        "        confidence_scores.append(confidence)\n",
        "\n",
        "        results[\"sample_responses\"].append({\n",
        "            \"prompt\": prompt[\"original_prompt\"],\n",
        "            \"reference\": prompt[\"original_reference\"],\n",
        "            \"response\": response,\n",
        "            \"accuracy\": accuracy,\n",
        "            \"hallucination_score\": hallucination_score,\n",
        "            \"confidence\": confidence\n",
        "        })\n",
        "\n",
        "    if accuracy_scores and hallucination_scores:\n",
        "        results[\"metrics\"] = {\n",
        "            \"accuracy\": np.mean(accuracy_scores),\n",
        "            \"hallucination_rate\": np.mean(hallucination_scores),\n",
        "            \"confidence\": np.mean(confidence_scores),\n",
        "            \"response_length\": np.mean([len(str(r[\"response\"])) for r in results[\"sample_responses\"]]),\n",
        "            \"consistency\": 1.0 - np.std(hallucination_scores) if len(hallucination_scores) > 1 else 1.0\n",
        "        }\n",
        "\n",
        "        # Calculate metrics by dataset\n",
        "        dataset_metrics = {}\n",
        "        for prompt in prompts:\n",
        "            dataset_name = prompt.get(\"dataset\", \"unknown\")\n",
        "            if dataset_name not in dataset_metrics:\n",
        "                dataset_metrics[dataset_name] = {\n",
        "                    \"accuracy_scores\": [],\n",
        "                    \"hallucination_scores\": [],\n",
        "                    \"confidence_scores\": []\n",
        "                }\n",
        "\n",
        "        for i, response_data in enumerate(results[\"sample_responses\"]):\n",
        "            dataset_name = prompts[i].get(\"dataset\", \"unknown\")\n",
        "            dataset_metrics[dataset_name][\"accuracy_scores\"].append(response_data[\"accuracy\"])\n",
        "            dataset_metrics[dataset_name][\"hallucination_scores\"].append(response_data[\"hallucination_score\"])\n",
        "            dataset_metrics[dataset_name][\"confidence_scores\"].append(response_data[\"confidence\"])\n",
        "\n",
        "        # Compute average metrics for each dataset\n",
        "        for dataset_name, metrics in dataset_metrics.items():\n",
        "            results[\"dataset_metrics\"][dataset_name] = {\n",
        "                \"accuracy\": np.mean(metrics[\"accuracy_scores\"]) if metrics[\"accuracy_scores\"] else 0,\n",
        "                \"hallucination_rate\": np.mean(metrics[\"hallucination_scores\"]) if metrics[\"hallucination_scores\"] else 0,\n",
        "                \"confidence\": np.mean(metrics[\"confidence_scores\"]) if metrics[\"confidence_scores\"] else 0,\n",
        "                \"sample_count\": len(metrics[\"accuracy_scores\"])\n",
        "            }\n",
        "\n",
        "    return results\n",
        "\n",
        "def generate_improvement_suggestions(metrics):\n",
        "    \"\"\"Generate suggestions based on evaluation results\"\"\"\n",
        "    suggestions = []\n",
        "\n",
        "    hallucination_rate = metrics.get(\"hallucination_rate\", 0)\n",
        "    accuracy = metrics.get(\"accuracy\", 0)\n",
        "    confidence = metrics.get(\"confidence\", 0)\n",
        "    consistency = metrics.get(\"consistency\", 0)\n",
        "\n",
        "    if hallucination_rate > 0.3:\n",
        "        suggestions.append({\n",
        "            \"category\": \"High Priority\",\n",
        "            \"suggestion\": \"Implement RAG with verified medical knowledge base\",\n",
        "            \"expected_impact\": \"40-60% reduction in hallucinations\"\n",
        "        })\n",
        "\n",
        "    if accuracy < 0.6:\n",
        "        suggestions.append({\n",
        "            \"category\": \"High Priority\",\n",
        "            \"suggestion\": \"Fine-tune with curated medical QA pairs and implement fact-checking\",\n",
        "            \"expected_impact\": \"30-50% accuracy improvement\"\n",
        "        })\n",
        "\n",
        "    if confidence < 0.6:\n",
        "        suggestions.append({\n",
        "            \"category\": \"Medium Priority\",\n",
        "            \"suggestion\": \"Add confidence calibration and uncertainty quantification\",\n",
        "            \"expected_impact\": \"Better reliability estimation and fewer overconfident errors\"\n",
        "        })\n",
        "\n",
        "    if consistency < 0.7:\n",
        "        suggestions.append({\n",
        "            \"category\": \"Medium Priority\",\n",
        "            \"suggestion\": \"Implement response consistency checks and self-verification\",\n",
        "            \"expected_impact\": \"More consistent and reliable responses\"\n",
        "        })\n",
        "\n",
        "    suggestions.append({\n",
        "        \"category\": \"General\",\n",
        "        \"suggestion\": \"Implement multi-step verification: claim extraction → fact checking → response generation\",\n",
        "        \"expected_impact\": \"Overall quality and reliability improvement\"\n",
        "    })\n",
        "\n",
        "    return suggestions"
      ],
      "metadata": {
        "id": "f7JWg7blCLkS"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Evaluation Functions"
      ],
      "metadata": {
        "id": "b5oL-nEcCVvN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_local_model(model_name, sample_count=3):\n",
        "    \"\"\"Evaluate a local model\"\"\"\n",
        "    print(f\"Evaluating local model: {model_name}...\")\n",
        "\n",
        "    try:\n",
        "        model_pipeline = load_local_model(model_name)\n",
        "\n",
        "        prompts = load_test_prompts(sample_count)\n",
        "\n",
        "        results = evaluate_model_responses(model_pipeline, prompts, model_name)\n",
        "\n",
        "        return results\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error evaluating {model_name}: {str(e)}\")\n",
        "        return {\n",
        "            \"model\": model_name,\n",
        "            \"error\": str(e),\n",
        "            \"metrics\": {\n",
        "                \"accuracy\": 0,\n",
        "                \"hallucination_rate\": 1.0,\n",
        "                \"confidence\": 0,\n",
        "                \"response_length\": 0,\n",
        "                \"consistency\": 0\n",
        "            },\n",
        "            \"evaluation_date\": datetime.now().isoformat()\n",
        "        }\n",
        "\n",
        "def evaluate_single_model(model_name, sample_count=3):\n",
        "    \"\"\"Evaluate a single local model\"\"\"\n",
        "    results = evaluate_local_model(model_name, sample_count)\n",
        "\n",
        "    # NEW: Evaluate on ALL medical datasets\n",
        "    dataset_results = {}\n",
        "    for dataset_name in [\"pubmedqa\", \"medqa\", \"mimic_cxr\"]:\n",
        "        try:\n",
        "            dataset_eval = evaluate_model_on_dataset(model_name, dataset_name, sample_count)\n",
        "            dataset_results[dataset_name] = dataset_eval\n",
        "        except Exception as e:\n",
        "            print(f\"Error evaluating on {dataset_name}: {str(e)}\")\n",
        "            dataset_results[dataset_name] = {\n",
        "                \"error\": str(e),\n",
        "                \"dataset\": dataset_name\n",
        "            }\n",
        "\n",
        "    baseline = {\n",
        "        \"accuracy\": 0.7,\n",
        "        \"hallucination_rate\": 0.25,\n",
        "        \"fact_score\": 0.75\n",
        "    }\n",
        "\n",
        "    if \"error\" not in results:\n",
        "        hallucination_reduction = (\n",
        "            ((baseline[\"hallucination_rate\"] - results[\"metrics\"][\"hallucination_rate\"]) / baseline[\"hallucination_rate\"] * 100)\n",
        "            if baseline[\"hallucination_rate\"] > 0\n",
        "            else 0\n",
        "        )\n",
        "\n",
        "        accuracy_improvement = (\n",
        "            ((results[\"metrics\"][\"accuracy\"] - baseline[\"accuracy\"]) / baseline[\"accuracy\"] * 100)\n",
        "            if baseline[\"accuracy\"] > 0\n",
        "            else 0\n",
        "        )\n",
        "\n",
        "        response_data = {\n",
        "            \"model\": model_name,\n",
        "            \"dataset\": \"combined_medical\",  # Changed from \"medical_qa\"\n",
        "            \"sample_count\": sample_count,\n",
        "            \"metrics\": results[\"metrics\"],\n",
        "            \"dataset_metrics\": dataset_results,  # NEW: Include all dataset results\n",
        "            \"baseline\": baseline,\n",
        "            \"improvement\": {\n",
        "                \"hallucination_reduction\": hallucination_reduction,\n",
        "                \"accuracy_improvement\": accuracy_improvement,\n",
        "            },\n",
        "            \"suggestions\": generate_improvement_suggestions(results[\"metrics\"]),\n",
        "            \"sample_responses\": results.get(\"sample_responses\", [])[:3],\n",
        "            \"evaluation_date\": datetime.now().isoformat()\n",
        "        }\n",
        "\n",
        "        return response_data\n",
        "    else:\n",
        "        return results\n",
        "\n",
        "def evaluate_all_models(sample_count=3):\n",
        "    \"\"\"Evaluate all available models\"\"\"\n",
        "    model_configs = get_model_configs()\n",
        "    all_results = {}\n",
        "\n",
        "    for model_name in model_configs.keys():\n",
        "        results = evaluate_single_model(model_name, sample_count)\n",
        "        all_results[model_name] = results\n",
        "\n",
        "        with open(f\"{model_name}_results.json\", \"w\") as f:\n",
        "            json.dump(results, f, indent=2)\n",
        "        print(f\"Results for {model_name} saved to {model_name}_results.json\")\n",
        "\n",
        "    with open(\"all_model_results.json\", \"w\") as f:\n",
        "        json.dump(all_results, f, indent=2)\n",
        "    print(\"All results saved to all_model_results.json\")\n",
        "\n",
        "    return all_results\n",
        "\n",
        "def evaluate_models_by_category(category, sample_count=3):\n",
        "    \"\"\"Evaluate models by category\"\"\"\n",
        "    categories = get_model_categories()\n",
        "\n",
        "    if category not in categories:\n",
        "        raise ValueError(f\"Unknown category: {category}\")\n",
        "\n",
        "    model_names = categories[category]\n",
        "    results = {}\n",
        "\n",
        "    for model_name in model_names:\n",
        "        results[model_name] = evaluate_local_model(model_name, sample_count)\n",
        "\n",
        "    with open(f\"{category}_results.json\", \"w\") as f:\n",
        "        json.dump(results, f, indent=2)\n",
        "    print(f\"Results for {category} saved to {category}_results.json\")\n",
        "\n",
        "    return results\n",
        "\n",
        "def evaluate_model_on_dataset(model_name, dataset_name, sample_count=3):\n",
        "    \"\"\"Evaluate a model on a specific dataset\"\"\"\n",
        "    print(f\"Evaluating {model_name} on {dataset_name} dataset...\")\n",
        "    try:\n",
        "        # Load local model\n",
        "        model = load_local_model(model_name)\n",
        "\n",
        "        # Load test prompts for specific dataset\n",
        "        prompts = load_test_prompts(sample_count, dataset_name)\n",
        "\n",
        "        # Evaluate model\n",
        "        results = evaluate_model_responses(model, prompts, model_name, dataset_name)\n",
        "\n",
        "        return results\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error evaluating {model_name} on {dataset_name}: {str(e)}\")\n",
        "        return {\n",
        "            \"model\": model_name,\n",
        "            \"dataset\": dataset_name,\n",
        "            \"error\": str(e),\n",
        "            \"metrics\": {\n",
        "                \"accuracy\": 0,\n",
        "                \"hallucination_rate\": 1.0,\n",
        "                \"confidence\": 0,\n",
        "                \"response_length\": 0,\n",
        "                \"consistency\": 0\n",
        "            },\n",
        "            \"evaluation_date\": datetime.now().isoformat()\n",
        "        }\n",
        "\n",
        "def evaluate_all_models_on_datasets(sample_count=3):\n",
        "    \"\"\"Evaluate all models on all datasets\"\"\"\n",
        "    model_configs = get_model_configs()\n",
        "    all_results = {}\n",
        "\n",
        "    for model_name in model_configs.keys():\n",
        "        model_results = {}\n",
        "\n",
        "        for dataset_name in [\"pubmedqa\", \"medqa\", \"mimic_cxr\", \"medical_qa\"]:\n",
        "            results = evaluate_model_on_dataset(model_name, dataset_name, sample_count)\n",
        "            model_results[dataset_name] = results\n",
        "\n",
        "        # Also evaluate on all datasets combined\n",
        "        combined_results = evaluate_single_model(model_name, sample_count)\n",
        "        model_results[\"combined\"] = combined_results\n",
        "\n",
        "        all_results[model_name] = model_results\n",
        "\n",
        "        # Save individual model results\n",
        "        with open(f\"{model_name}_dataset_results.json\", \"w\") as f:\n",
        "            json.dump(model_results, f, indent=2)\n",
        "        print(f\"Results for {model_name} saved to {model_name}_dataset_results.json\")\n",
        "\n",
        "    # Save all results together\n",
        "    with open(\"all_models_dataset_results.json\", \"w\") as f:\n",
        "        json.dump(all_results, f, indent=2)\n",
        "    print(\"All dataset results saved to all_models_dataset_results.json\")\n",
        "\n",
        "    return all_results"
      ],
      "metadata": {
        "id": "2JVN0x4aCTjw"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualization Functions"
      ],
      "metadata": {
        "id": "iamMaWn2Cbln"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_bar_chart_base64(model_results, metric=\"accuracy\"):\n",
        "    \"\"\"Create bar chart and return as base64 string\"\"\"\n",
        "    valid_models = {k: v for k, v in model_results.items() if \"error\" not in v}\n",
        "\n",
        "    if not valid_models:\n",
        "        return None\n",
        "\n",
        "    models = list(valid_models.keys())\n",
        "    values = [valid_models[model][\"metrics\"].get(metric, 0) for model in models]\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(12, 6))\n",
        "    bars = ax.bar(models, values, color=['#4CAF50', '#2196F3', '#FF9800', '#E91E63', '#9C27B0'])\n",
        "\n",
        "    # Customize the chart\n",
        "    ax.set_ylabel(metric.replace('_', ' ').title(), fontsize=12)\n",
        "    ax.set_title(f'Model Comparison - {metric.replace(\"_\", \" \").title()}', fontsize=14, fontweight='bold')\n",
        "    ax.set_ylim(0, 1)\n",
        "\n",
        "    # Add value labels on bars\n",
        "    for i, v in enumerate(values):\n",
        "        ax.text(i, v + 0.01, f'{v:.2f}', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Convert to base64\n",
        "    buf = BytesIO()\n",
        "    plt.savefig(buf, format='png', dpi=150, bbox_inches='tight')\n",
        "    buf.seek(0)\n",
        "    img_base64 = base64.b64encode(buf.getvalue()).decode('utf-8')\n",
        "    plt.close()\n",
        "\n",
        "    return img_base64"
      ],
      "metadata": {
        "id": "1exDfJ11CavL"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# evaluate data, visualization"
      ],
      "metadata": {
        "id": "JtqUgfDsIZz1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import base64\n",
        "import zipfile\n",
        "from google.colab import files\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def create_ui_export_data(model_results, model_name):\n",
        "    \"\"\"Create the specialized UI export data that includes medical datasets\"\"\"\n",
        "    if \"error\" in model_results:\n",
        "        return {\n",
        "            \"model\": model_name,\n",
        "            \"error\": model_results[\"error\"],\n",
        "            \"evaluation_date\": model_results.get(\"evaluation_date\", datetime.now().isoformat())\n",
        "        }\n",
        "\n",
        "    # Extract sample responses for UI display\n",
        "    sample_responses = []\n",
        "    for i, response_data in enumerate(model_results.get(\"sample_responses\", [])[:5]):\n",
        "        sample_responses.append({\n",
        "            \"id\": i + 1,\n",
        "            \"prompt\": response_data[\"prompt\"],\n",
        "            \"reference\": response_data[\"reference\"],\n",
        "            \"response\": response_data[\"response\"],\n",
        "            \"accuracy\": response_data[\"accuracy\"],\n",
        "            \"hallucination_score\": response_data[\"hallucination_score\"],\n",
        "            \"dataset\": response_data.get(\"dataset\", \"medical_qa\")  # NEW: Include dataset info\n",
        "        })\n",
        "\n",
        "    # Extract dataset metrics for UI\n",
        "    dataset_performance = {}\n",
        "    for dataset_name, dataset_data in model_results.get(\"dataset_metrics\", {}).items():\n",
        "        if \"metrics\" in dataset_data:\n",
        "            dataset_performance[dataset_name] = dataset_data[\"metrics\"]\n",
        "\n",
        "    # Create the UI export data structure\n",
        "    ui_export_data = {\n",
        "        \"model\": model_name,\n",
        "        \"evaluation_date\": model_results.get(\"evaluation_date\", datetime.now().isoformat()),\n",
        "        \"metrics\": model_results.get(\"metrics\", {}),\n",
        "        \"dataset_metrics\": dataset_performance,  # NEW: Include dataset performance\n",
        "        \"dataset_details\": model_results.get(\"dataset_metrics\", {}),  # NEW: Full dataset details\n",
        "        \"sample_responses\": sample_responses,\n",
        "        \"suggestions\": model_results.get(\"suggestions\", []),\n",
        "        \"improvement\": model_results.get(\"improvement\", {}),\n",
        "        \"baseline\": model_results.get(\"baseline\", {})\n",
        "    }\n",
        "\n",
        "    return ui_export_data\n",
        "\n",
        "\n",
        "def create_visualization_directory_structure(model_name):\n",
        "    \"\"\"Create directory structure for storing visualization files - FIXED STRUCTURE\"\"\"\n",
        "    # Create a unified directory structure\n",
        "    base_dir = f\"model_evaluation_{model_name}\"\n",
        "\n",
        "    sub_dirs = {\n",
        "        'charts': f\"{base_dir}/charts\",\n",
        "        'data': f\"{base_dir}/data\",\n",
        "        'tables': f\"{base_dir}/tables\",\n",
        "        'dataset_analysis': f\"{base_dir}/dataset_analysis\"\n",
        "    }\n",
        "\n",
        "    # Create all directories\n",
        "    for dir_path in sub_dirs.values():\n",
        "        os.makedirs(dir_path, exist_ok=True)\n",
        "        print(f\"Created directory: {dir_path}\")\n",
        "\n",
        "    return base_dir, sub_dirs\n",
        "\n",
        "def export_visualizations_to_directories(model_results, model_name):\n",
        "    \"\"\"Export all visualizations to organized directory structure - FIXED VERSION\"\"\"\n",
        "    try:\n",
        "        # Handle different input types\n",
        "        if isinstance(model_results, dict) and model_name in model_results:\n",
        "            model_data = model_results[model_name]\n",
        "        elif isinstance(model_results, dict) and len(model_results) == 1:\n",
        "            model_data = next(iter(model_results.values()))\n",
        "        else:\n",
        "            model_data = model_results\n",
        "\n",
        "        # Check if we have valid data\n",
        "        if not isinstance(model_data, dict) or \"error\" in model_data:\n",
        "            print(f\"Error: Invalid model data for {model_name}\")\n",
        "            return None, []\n",
        "\n",
        "        base_dir, sub_dirs = create_visualization_directory_structure(model_name)\n",
        "        exported_files = []\n",
        "\n",
        "        # Create and save UI export data\n",
        "        ui_export_data = create_ui_export_data(model_data, model_name)\n",
        "        ui_export_filename = f\"{sub_dirs['data']}/{model_name}_ui_export_data.json\"\n",
        "        with open(ui_export_filename, \"w\") as f:\n",
        "            json.dump(ui_export_data, f, indent=2)\n",
        "        exported_files.append(ui_export_filename)\n",
        "\n",
        "        # Create and save comprehensive results\n",
        "        comprehensive_filename = f\"{sub_dirs['data']}/{model_name}_comprehensive_results.json\"\n",
        "        with open(comprehensive_filename, \"w\") as f:\n",
        "            json.dump(model_data, f, indent=2)\n",
        "        exported_files.append(comprehensive_filename)\n",
        "\n",
        "        # For single model, create a dict format for visualization functions\n",
        "        model_results_dict = {model_name: model_data}\n",
        "\n",
        "        # Bar charts for key metrics\n",
        "        for metric in [\"accuracy\", \"hallucination_rate\", \"confidence\"]:\n",
        "            img_data = create_bar_chart_base64(model_results_dict, metric)\n",
        "            if img_data:\n",
        "                filename = f\"{sub_dirs['charts']}/{metric}_bar_chart.png\"\n",
        "                with open(filename, \"wb\") as f:\n",
        "                    f.write(base64.b64decode(img_data))\n",
        "                exported_files.append(filename)\n",
        "                print(f\"Created chart: {filename}\")\n",
        "\n",
        "        # Radar chart\n",
        "        radar_img = create_radar_chart_base64(model_results_dict)\n",
        "        if radar_img:\n",
        "            filename = f\"{sub_dirs['charts']}/radar_chart.png\"\n",
        "            with open(filename, \"wb\") as f:\n",
        "                f.write(base64.b64decode(radar_img))\n",
        "            exported_files.append(filename)\n",
        "            print(f\"Created chart: {filename}\")\n",
        "\n",
        "        # Comparison table\n",
        "        comparison_table = create_comparison_table(model_results_dict)\n",
        "        if not comparison_table.empty:\n",
        "            html_filename = f\"{sub_dirs['tables']}/comparison_table.html\"\n",
        "            with open(html_filename, \"w\") as f:\n",
        "                f.write(comparison_table.to_html(classes='table table-striped', index=False))\n",
        "            exported_files.append(html_filename)\n",
        "            print(f\"Created table: {html_filename}\")\n",
        "\n",
        "        # Additional visualizations for medical datasets if available\n",
        "        if \"dataset_metrics\" in model_data and model_data[\"dataset_metrics\"]:\n",
        "            # Dataset comparison chart\n",
        "            dataset_chart = create_dataset_comparison_chart(model_results_dict)\n",
        "            if dataset_chart:\n",
        "                filename = f\"{sub_dirs['charts']}/dataset_comparison_chart.png\"\n",
        "                with open(filename, \"wb\") as f:\n",
        "                    f.write(base64.b64decode(dataset_chart))\n",
        "                exported_files.append(filename)\n",
        "                print(f\"Created chart: {filename}\")\n",
        "\n",
        "            # Individual dataset radar charts\n",
        "            for dataset_name in [\"pubmedqa\", \"medqa\", \"mimic_cxr\"]:\n",
        "                if dataset_name in model_data.get(\"dataset_metrics\", {}):\n",
        "                    dataset_radar = create_dataset_radar_chart(model_results_dict, dataset_name)\n",
        "                    if dataset_radar:\n",
        "                        filename = f\"{sub_dirs['charts']}/{dataset_name}_radar_chart.png\"\n",
        "                        with open(filename, \"wb\") as f:\n",
        "                            f.write(base64.b64decode(dataset_radar))\n",
        "                        exported_files.append(filename)\n",
        "                        print(f\"Created chart: {filename}\")\n",
        "\n",
        "        print(f\"Exported {len(exported_files)} files to {base_dir}/ directory structure\")\n",
        "        return base_dir, exported_files\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in export_visualizations_to_directories: {str(e)}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return None, []\n",
        "\n",
        "def create_zip_from_directory(base_dir):\n",
        "    \"\"\"Create ZIP archive from directory structure - SIMPLIFIED\"\"\"\n",
        "    zip_filename = f\"{base_dir}.zip\"\n",
        "\n",
        "    with zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "        for root, dirs, files in os.walk(base_dir):\n",
        "            for file in files:\n",
        "                file_path = os.path.join(root, file)\n",
        "                # Add file to zip with relative path\n",
        "                arcname = os.path.relpath(file_path, base_dir)\n",
        "                zipf.write(file_path, arcname)\n",
        "\n",
        "    print(f\"Created ZIP archive: {zip_filename}\")\n",
        "    return zip_filename\n",
        "\n",
        "def create_radar_chart_base64(model_results):\n",
        "    \"\"\"Create radar chart comparing multiple metrics across models - UPDATED for single model\"\"\"\n",
        "    valid_models = {k: v for k, v in model_results.items() if \"error\" not in v}\n",
        "\n",
        "    # Handle single model case by creating a minimal comparison\n",
        "    if len(valid_models) == 1:\n",
        "        # For single model, create a radar chart with just that model\n",
        "        model_name, results = next(iter(valid_models.items()))\n",
        "        metrics = ['accuracy', 'confidence', 'consistency']\n",
        "        labels = ['Accuracy', 'Confidence', 'Consistency']\n",
        "\n",
        "        fig, ax = plt.subplots(figsize=(8, 8), subplot_kw=dict(polar=True))\n",
        "\n",
        "        values = [results[\"metrics\"].get(metric, 0) for metric in metrics]\n",
        "        values += values[:1]  # Close the radar chart\n",
        "\n",
        "        angles = np.linspace(0, 2 * np.pi, len(metrics), endpoint=False).tolist()\n",
        "        angles += angles[:1]\n",
        "\n",
        "        ax.plot(angles, values, 'o-', linewidth=2, label=model_name, color='#4CAF50')\n",
        "        ax.fill(angles, values, alpha=0.1, color='#4CAF50')\n",
        "\n",
        "        ax.set_thetagrids(np.degrees(angles[:-1]), labels)\n",
        "        ax.set_ylim(0, 1)\n",
        "        ax.set_title(f'{model_name} Performance Radar Chart', size=14, fontweight='bold')\n",
        "        ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1))\n",
        "        plt.tight_layout()\n",
        "\n",
        "        # Convert to base64\n",
        "        buf = BytesIO()\n",
        "        plt.savefig(buf, format='png', dpi=150, bbox_inches='tight')\n",
        "        buf.seek(0)\n",
        "        img_base64 = base64.b64encode(buf.getvalue()).decode('utf-8')\n",
        "        plt.close()\n",
        "\n",
        "        return img_base64\n",
        "\n",
        "    elif len(valid_models) >= 2:\n",
        "        # Original multi-model code\n",
        "        metrics = ['accuracy', 'confidence', 'consistency']\n",
        "        labels = ['Accuracy', 'Confidence', 'Consistency']\n",
        "\n",
        "        fig, ax = plt.subplots(figsize=(10, 10), subplot_kw=dict(polar=True))\n",
        "\n",
        "        colors = ['#4CAF50', '#2196F3', '#FF9800', '#E91E63', '#9C27B0']\n",
        "\n",
        "        for i, (model_name, results) in enumerate(valid_models.items()):\n",
        "            values = [results[\"metrics\"].get(metric, 0) for metric in metrics]\n",
        "            values += values[:1]  # Close the radar chart\n",
        "\n",
        "            angles = np.linspace(0, 2 * np.pi, len(metrics), endpoint=False).tolist()\n",
        "            angles += angles[:1]\n",
        "\n",
        "            ax.plot(angles, values, 'o-', linewidth=2, label=model_name, color=colors[i % len(colors)])\n",
        "            ax.fill(angles, values, alpha=0.1, color=colors[i % len(colors)])\n",
        "\n",
        "        ax.set_thetagrids(np.degrees(angles[:-1]), labels)\n",
        "        ax.set_ylim(0, 1)\n",
        "        ax.set_title('Model Performance Radar Chart', size=14, fontweight='bold')\n",
        "        ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1))\n",
        "        plt.tight_layout()\n",
        "\n",
        "        # Convert to base64\n",
        "        buf = BytesIO()\n",
        "        plt.savefig(buf, format='png', dpi=150, bbox_inches='tight')\n",
        "        buf.seek(0)\n",
        "        img_base64 = base64.b64encode(buf.getvalue()).decode('utf-8')\n",
        "        plt.close()\n",
        "\n",
        "        return img_base64\n",
        "\n",
        "    return None\n",
        "\n",
        "def create_dataset_comparison_chart(model_results):\n",
        "    \"\"\"Create chart comparing performance across medical datasets - UPDATED\"\"\"\n",
        "    valid_models = {k: v for k, v in model_results.items() if \"error\" not in v and \"dataset_metrics\" in v}\n",
        "\n",
        "    if not valid_models:\n",
        "        return None\n",
        "\n",
        "    # Get all medical dataset names\n",
        "    dataset_names = [\"pubmedqa\", \"medqa\", \"mimic_cxr\"]\n",
        "\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "    # Accuracy by dataset\n",
        "    for model_name, results in valid_models.items():\n",
        "        accuracies = []\n",
        "        for dataset in dataset_names:\n",
        "            if dataset in results.get(\"dataset_metrics\", {}):\n",
        "                accuracies.append(results[\"dataset_metrics\"][dataset].get(\"metrics\", {}).get(\"accuracy\", 0))\n",
        "            else:\n",
        "                accuracies.append(0)\n",
        "\n",
        "        axes[0].plot(dataset_names, accuracies, 'o-', label=model_name, linewidth=2, markersize=8)\n",
        "\n",
        "    axes[0].set_title('Accuracy Across Medical Datasets', fontsize=14, fontweight='bold')\n",
        "    axes[0].set_ylabel('Accuracy')\n",
        "    axes[0].tick_params(axis='x', rotation=45)\n",
        "    axes[0].legend()\n",
        "    axes[0].grid(True, alpha=0.3)\n",
        "    axes[0].set_ylim(0, 1)\n",
        "\n",
        "    # Hallucination rate by dataset\n",
        "    for model_name, results in valid_models.items():\n",
        "        hall_rates = []\n",
        "        for dataset in dataset_names:\n",
        "            if dataset in results.get(\"dataset_metrics\", {}):\n",
        "                hall_rates.append(results[\"dataset_metrics\"][dataset].get(\"metrics\", {}).get(\"hallucination_rate\", 0))\n",
        "            else:\n",
        "                hall_rates.append(0)\n",
        "\n",
        "        axes[1].plot(dataset_names, hall_rates, 'o-', label=model_name, linewidth=2, markersize=8)\n",
        "\n",
        "    axes[1].set_title('Hallucination Rate Across Medical Datasets', fontsize=14, fontweight='bold')\n",
        "    axes[1].set_ylabel('Hallucination Rate')\n",
        "    axes[1].tick_params(axis='x', rotation=45)\n",
        "    axes[1].legend()\n",
        "    axes[1].grid(True, alpha=0.3)\n",
        "    axes[1].set_ylim(0, 1)\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Convert to base64\n",
        "    buf = BytesIO()\n",
        "    plt.savefig(buf, format='png', dpi=150, bbox_inches='tight')\n",
        "    buf.seek(0)\n",
        "    img_base64 = base64.b64encode(buf.getvalue()).decode('utf-8')\n",
        "    plt.close()\n",
        "\n",
        "    return img_base64\n",
        "\n",
        "\n",
        "def create_dataset_radar_chart(model_results, dataset_name):\n",
        "    \"\"\"Create radar chart for a specific dataset\"\"\"\n",
        "    valid_models = {k: v for k, v in model_results.items() if \"error\" not in v and \"dataset_metrics\" in v}\n",
        "\n",
        "    if not valid_models or dataset_name not in next(iter(valid_models.values()))[\"dataset_metrics\"]:\n",
        "        return None\n",
        "\n",
        "    metrics = ['accuracy', 'confidence']\n",
        "    labels = ['Accuracy', 'Confidence']\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(8, 8), subplot_kw=dict(polar=True))\n",
        "\n",
        "    colors = ['#4CAF50', '#2196F3', '#FF9800', '#E91E63', '#9C27B0']\n",
        "\n",
        "    for i, (model_name, results) in enumerate(valid_models.items()):\n",
        "        if dataset_name in results[\"dataset_metrics\"]:\n",
        "            values = [results[\"dataset_metrics\"][dataset_name].get(metric, 0) for metric in metrics]\n",
        "            values += values[:1]  # Close the radar chart\n",
        "\n",
        "            angles = np.linspace(0, 2 * np.pi, len(metrics), endpoint=False).tolist()\n",
        "            angles += angles[:1]\n",
        "\n",
        "            ax.plot(angles, values, 'o-', linewidth=2, label=model_name, color=colors[i % len(colors)])\n",
        "            ax.fill(angles, values, alpha=0.1, color=colors[i % len(colors)])\n",
        "\n",
        "    ax.set_thetagrids(np.degrees(angles[:-1]), labels)\n",
        "    ax.set_ylim(0, 1)\n",
        "    ax.set_title(f'Performance on {dataset_name.upper()} Dataset', size=14, fontweight='bold')\n",
        "    ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1))\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Convert to base64\n",
        "    buf = BytesIO()\n",
        "    plt.savefig(buf, format='png', dpi=150, bbox_inches='tight')\n",
        "    buf.seek(0)\n",
        "    img_base64 = base64.b64encode(buf.getvalue()).decode('utf-8')\n",
        "    plt.close()\n",
        "\n",
        "    return img_base64\n",
        "\n",
        "def create_comparison_table(model_results):\n",
        "    \"\"\"Create comprehensive comparison table\"\"\"\n",
        "    data = []\n",
        "    for model_name, results in model_results.items():\n",
        "        if \"error\" not in results:\n",
        "            data.append({\n",
        "                \"Model\": model_name,\n",
        "                \"Accuracy\": f\"{results['metrics'].get('accuracy', 0):.3f}\",\n",
        "                \"Hallucination Rate\": f\"{results['metrics'].get('hallucination_rate', 0):.3f}\",\n",
        "                \"Confidence\": f\"{results['metrics'].get('confidence', 0):.3f}\",\n",
        "                \"Response Length\": f\"{results['metrics'].get('response_length', 0):.1f}\",\n",
        "                \"Consistency\": f\"{results['metrics'].get('consistency', 0):.3f}\",\n",
        "                \"Sample Count\": results.get('sample_count', 0)\n",
        "            })\n",
        "\n",
        "    return pd.DataFrame(data)"
      ],
      "metadata": {
        "id": "e3VyQKevIWac"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
        "sample_count = 2\n",
        "\n",
        "def clear_gpu_cache():\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "        torch.cuda.synchronize()\n",
        "\n",
        "# List of free models to evaluate\n",
        "free_models = [\"llama-2-7b\", \"mistral-7b\", \"qwen-7b\", \"meditron-7b\", \"biomedgpt\"]\n",
        "\n",
        "# Evaluate a specific model\n",
        "model_name = \"mistral-7b\"  # Change this to evaluate different models\n",
        "clear_gpu_cache()\n",
        "model_result = evaluate_single_model(model_name, sample_count)\n",
        "\n",
        "# Export visualizations\n",
        "base_dir, exported_files = export_visualizations_to_directories(model_result, model_name)\n",
        "\n",
        "# Print what files were created\n",
        "print(\"Files created:\")\n",
        "for file in exported_files:\n",
        "    print(f\"  - {file}\")\n",
        "\n",
        "# Create and download zip\n",
        "zip_filename = create_zip_from_directory(base_dir)\n",
        "files.download(zip_filename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yXncwdgQIuNb",
        "outputId": "292f470c-89e8-49ae-d7ec-c4198ad7d9b6"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating local model: mistral-7b...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_http.py\", line 409, in hf_raise_for_status\n",
            "    response.raise_for_status()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/requests/models.py\", line 1026, in raise_for_status\n",
            "    raise HTTPError(http_error_msg, response=self)\n",
            "requests.exceptions.HTTPError: 401 Client Error: Unauthorized for url: https://huggingface.co/mistralai/Mistral-7B-v0.1/resolve/main/config.json\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py\", line 478, in cached_files\n",
            "    hf_hub_download(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\", line 1010, in hf_hub_download\n",
            "    return _hf_hub_download_to_cache_dir(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\", line 1117, in _hf_hub_download_to_cache_dir\n",
            "    _raise_on_head_call_error(head_call_error, force_download, local_files_only)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\", line 1658, in _raise_on_head_call_error\n",
            "    raise head_call_error\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\", line 1546, in _get_metadata_or_catch_error\n",
            "    metadata = get_hf_file_metadata(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\", line 1463, in get_hf_file_metadata\n",
            "    r = _request_wrapper(\n",
            "        ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\", line 286, in _request_wrapper\n",
            "    response = _request_wrapper(\n",
            "               ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\", line 310, in _request_wrapper\n",
            "    hf_raise_for_status(response)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_http.py\", line 482, in hf_raise_for_status\n",
            "    raise _format(HfHubHTTPError, str(e), response) from e\n",
            "huggingface_hub.errors.HfHubHTTPError: 401 Client Error: Unauthorized for url: https://huggingface.co/mistralai/Mistral-7B-v0.1/resolve/main/config.json (Request ID: Root=1-68c000fa-16c0c5d6275a87b673498474;440236e9-7be8-4943-8aaa-f68a46e0b5b3)\n",
            "\n",
            "Invalid credentials in Authorization header\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-3602496430.py\", line 70, in load_local_model\n",
            "    tokenizer = AutoTokenizer.from_pretrained(model_id, **tokenizer_kwargs)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/models/auto/tokenization_auto.py\", line 1078, in from_pretrained\n",
            "    config = AutoConfig.from_pretrained(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/models/auto/configuration_auto.py\", line 1288, in from_pretrained\n",
            "    config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)\n",
            "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/configuration_utils.py\", line 662, in get_config_dict\n",
            "    config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)\n",
            "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/configuration_utils.py\", line 721, in _get_config_dict\n",
            "    resolved_config_file = cached_file(\n",
            "                           ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py\", line 321, in cached_file\n",
            "    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py\", line 562, in cached_files\n",
            "    raise OSError(f\"There was a specific connection error when trying to load {path_or_repo_id}:\\n{e}\") from e\n",
            "OSError: There was a specific connection error when trying to load mistralai/Mistral-7B-v0.1:\n",
            "401 Client Error: Unauthorized for url: https://huggingface.co/mistralai/Mistral-7B-v0.1/resolve/main/config.json (Request ID: Root=1-68c000fa-16c0c5d6275a87b673498474;440236e9-7be8-4943-8aaa-f68a46e0b5b3)\n",
            "\n",
            "Invalid credentials in Authorization header\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error loading mistral-7b: There was a specific connection error when trying to load mistralai/Mistral-7B-v0.1:\n",
            "401 Client Error: Unauthorized for url: https://huggingface.co/mistralai/Mistral-7B-v0.1/resolve/main/config.json (Request ID: Root=1-68c000fa-16c0c5d6275a87b673498474;440236e9-7be8-4943-8aaa-f68a46e0b5b3)\n",
            "\n",
            "Invalid credentials in Authorization header\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating mistral-7b:   0%|          | 0/8 [00:00<?, ?it/s]WARNING:sentence_transformers.SentenceTransformer:No sentence-transformers model found with name sentence-transformers/all-mpnet-base-v2. Creating a new one with mean pooling.\n",
            "Evaluating mistral-7b:  12%|█▎        | 1/8 [00:00<00:04,  1.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error in generation: There was a specific connection error when trying to load sentence-transformers/all-mpnet-base-v2:\n",
            "401 Client Error: Unauthorized for url: https://huggingface.co/sentence-transformers/all-mpnet-base-v2/resolve/main/config.json (Request ID: Root=1-68c000fb-1295a62872b74fb1237f07b5;457b8357-4249-4265-931e-808dbcddab66)\n",
            "\n",
            "Invalid credentials in Authorization header\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sentence_transformers.SentenceTransformer:No sentence-transformers model found with name sentence-transformers/all-mpnet-base-v2. Creating a new one with mean pooling.\n",
            "Evaluating mistral-7b:  25%|██▌       | 2/8 [00:01<00:04,  1.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error in generation: There was a specific connection error when trying to load sentence-transformers/all-mpnet-base-v2:\n",
            "401 Client Error: Unauthorized for url: https://huggingface.co/sentence-transformers/all-mpnet-base-v2/resolve/main/config.json (Request ID: Root=1-68c000fc-29d53cbc5c93b6a1442d7e2f;83bcb34b-eaab-414f-ad20-d97c8c417855)\n",
            "\n",
            "Invalid credentials in Authorization header\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sentence_transformers.SentenceTransformer:No sentence-transformers model found with name sentence-transformers/all-mpnet-base-v2. Creating a new one with mean pooling.\n",
            "Evaluating mistral-7b:  38%|███▊      | 3/8 [00:02<00:03,  1.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error in generation: There was a specific connection error when trying to load sentence-transformers/all-mpnet-base-v2:\n",
            "401 Client Error: Unauthorized for url: https://huggingface.co/sentence-transformers/all-mpnet-base-v2/resolve/main/config.json (Request ID: Root=1-68c000fd-080a5c97686a4dfb1dc2bee4;5fa4ca96-074e-461b-94dd-49ecf8951663)\n",
            "\n",
            "Invalid credentials in Authorization header\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sentence_transformers.SentenceTransformer:No sentence-transformers model found with name sentence-transformers/all-mpnet-base-v2. Creating a new one with mean pooling.\n",
            "Evaluating mistral-7b:  50%|█████     | 4/8 [00:03<00:03,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error in generation: There was a specific connection error when trying to load sentence-transformers/all-mpnet-base-v2:\n",
            "401 Client Error: Unauthorized for url: https://huggingface.co/sentence-transformers/all-mpnet-base-v2/resolve/main/config.json (Request ID: Root=1-68c000fd-110d2208564071e1548fa341;77499da3-5c16-4b79-8cec-cd58fc72935a)\n",
            "\n",
            "Invalid credentials in Authorization header\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sentence_transformers.SentenceTransformer:No sentence-transformers model found with name sentence-transformers/all-mpnet-base-v2. Creating a new one with mean pooling.\n",
            "Evaluating mistral-7b:  62%|██████▎   | 5/8 [00:03<00:02,  1.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error in generation: There was a specific connection error when trying to load sentence-transformers/all-mpnet-base-v2:\n",
            "401 Client Error: Unauthorized for url: https://huggingface.co/sentence-transformers/all-mpnet-base-v2/resolve/main/config.json (Request ID: Root=1-68c000fe-2bc5e57802d29d461bd337d2;d73ddb9d-f0b9-4c8c-ac51-4e316415fc20)\n",
            "\n",
            "Invalid credentials in Authorization header\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sentence_transformers.SentenceTransformer:No sentence-transformers model found with name sentence-transformers/all-mpnet-base-v2. Creating a new one with mean pooling.\n",
            "Evaluating mistral-7b:  75%|███████▌  | 6/8 [00:04<00:01,  1.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error in generation: There was a specific connection error when trying to load sentence-transformers/all-mpnet-base-v2:\n",
            "401 Client Error: Unauthorized for url: https://huggingface.co/sentence-transformers/all-mpnet-base-v2/resolve/main/config.json (Request ID: Root=1-68c000ff-25e3797e736a8b7e40a13e93;fe50ffb6-081c-45dd-a48b-c31fae972f44)\n",
            "\n",
            "Invalid credentials in Authorization header\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sentence_transformers.SentenceTransformer:No sentence-transformers model found with name sentence-transformers/all-mpnet-base-v2. Creating a new one with mean pooling.\n",
            "Evaluating mistral-7b:  88%|████████▊ | 7/8 [00:05<00:00,  1.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error in generation: There was a specific connection error when trying to load sentence-transformers/all-mpnet-base-v2:\n",
            "401 Client Error: Unauthorized for url: https://huggingface.co/sentence-transformers/all-mpnet-base-v2/resolve/main/config.json (Request ID: Root=1-68c00100-5d39c9d80672255c2c3becf9;f271ea96-dc19-4624-886e-21ca4bedfdd9)\n",
            "\n",
            "Invalid credentials in Authorization header\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sentence_transformers.SentenceTransformer:No sentence-transformers model found with name sentence-transformers/all-mpnet-base-v2. Creating a new one with mean pooling.\n",
            "Evaluating mistral-7b: 100%|██████████| 8/8 [00:06<00:00,  1.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error in generation: There was a specific connection error when trying to load sentence-transformers/all-mpnet-base-v2:\n",
            "401 Client Error: Unauthorized for url: https://huggingface.co/sentence-transformers/all-mpnet-base-v2/resolve/main/config.json (Request ID: Root=1-68c00100-51051ed97e812c8d594d87a9;81166b2a-7c56-4bd6-ab4e-cc976f2bb002)\n",
            "\n",
            "Invalid credentials in Authorization header\n",
            "Evaluating mistral-7b on pubmedqa dataset...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_http.py\", line 409, in hf_raise_for_status\n",
            "    response.raise_for_status()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/requests/models.py\", line 1026, in raise_for_status\n",
            "    raise HTTPError(http_error_msg, response=self)\n",
            "requests.exceptions.HTTPError: 401 Client Error: Unauthorized for url: https://huggingface.co/mistralai/Mistral-7B-v0.1/resolve/main/config.json\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py\", line 478, in cached_files\n",
            "    hf_hub_download(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\", line 1010, in hf_hub_download\n",
            "    return _hf_hub_download_to_cache_dir(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\", line 1117, in _hf_hub_download_to_cache_dir\n",
            "    _raise_on_head_call_error(head_call_error, force_download, local_files_only)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\", line 1658, in _raise_on_head_call_error\n",
            "    raise head_call_error\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\", line 1546, in _get_metadata_or_catch_error\n",
            "    metadata = get_hf_file_metadata(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\", line 1463, in get_hf_file_metadata\n",
            "    r = _request_wrapper(\n",
            "        ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\", line 286, in _request_wrapper\n",
            "    response = _request_wrapper(\n",
            "               ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\", line 310, in _request_wrapper\n",
            "    hf_raise_for_status(response)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_http.py\", line 482, in hf_raise_for_status\n",
            "    raise _format(HfHubHTTPError, str(e), response) from e\n",
            "huggingface_hub.errors.HfHubHTTPError: 401 Client Error: Unauthorized for url: https://huggingface.co/mistralai/Mistral-7B-v0.1/resolve/main/config.json (Request ID: Root=1-68c00101-37c3d0083c1eac0f75e088dc;ea8885a7-b482-4d62-93f6-891872ce51c5)\n",
            "\n",
            "Invalid credentials in Authorization header\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-3602496430.py\", line 70, in load_local_model\n",
            "    tokenizer = AutoTokenizer.from_pretrained(model_id, **tokenizer_kwargs)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/models/auto/tokenization_auto.py\", line 1078, in from_pretrained\n",
            "    config = AutoConfig.from_pretrained(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/models/auto/configuration_auto.py\", line 1288, in from_pretrained\n",
            "    config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)\n",
            "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/configuration_utils.py\", line 662, in get_config_dict\n",
            "    config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)\n",
            "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/configuration_utils.py\", line 721, in _get_config_dict\n",
            "    resolved_config_file = cached_file(\n",
            "                           ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py\", line 321, in cached_file\n",
            "    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py\", line 562, in cached_files\n",
            "    raise OSError(f\"There was a specific connection error when trying to load {path_or_repo_id}:\\n{e}\") from e\n",
            "OSError: There was a specific connection error when trying to load mistralai/Mistral-7B-v0.1:\n",
            "401 Client Error: Unauthorized for url: https://huggingface.co/mistralai/Mistral-7B-v0.1/resolve/main/config.json (Request ID: Root=1-68c00101-37c3d0083c1eac0f75e088dc;ea8885a7-b482-4d62-93f6-891872ce51c5)\n",
            "\n",
            "Invalid credentials in Authorization header\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error loading mistral-7b: There was a specific connection error when trying to load mistralai/Mistral-7B-v0.1:\n",
            "401 Client Error: Unauthorized for url: https://huggingface.co/mistralai/Mistral-7B-v0.1/resolve/main/config.json (Request ID: Root=1-68c00101-37c3d0083c1eac0f75e088dc;ea8885a7-b482-4d62-93f6-891872ce51c5)\n",
            "\n",
            "Invalid credentials in Authorization header\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating mistral-7b:   0%|          | 0/2 [00:00<?, ?it/s]WARNING:sentence_transformers.SentenceTransformer:No sentence-transformers model found with name sentence-transformers/all-mpnet-base-v2. Creating a new one with mean pooling.\n",
            "Evaluating mistral-7b:  50%|█████     | 1/2 [00:00<00:00,  1.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error in generation: There was a specific connection error when trying to load sentence-transformers/all-mpnet-base-v2:\n",
            "401 Client Error: Unauthorized for url: https://huggingface.co/sentence-transformers/all-mpnet-base-v2/resolve/main/config.json (Request ID: Root=1-68c00102-4e0ebfba64e8651516deffb4;42de735b-fa5d-4d83-a83d-818c734c5922)\n",
            "\n",
            "Invalid credentials in Authorization header\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sentence_transformers.SentenceTransformer:No sentence-transformers model found with name sentence-transformers/all-mpnet-base-v2. Creating a new one with mean pooling.\n",
            "Evaluating mistral-7b: 100%|██████████| 2/2 [00:01<00:00,  1.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error in generation: There was a specific connection error when trying to load sentence-transformers/all-mpnet-base-v2:\n",
            "401 Client Error: Unauthorized for url: https://huggingface.co/sentence-transformers/all-mpnet-base-v2/resolve/main/config.json (Request ID: Root=1-68c00103-3bbb96494847025f2228f2eb;5f1e709a-a80e-49e8-82b3-398697220d99)\n",
            "\n",
            "Invalid credentials in Authorization header\n",
            "Evaluating mistral-7b on medqa dataset...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_http.py\", line 409, in hf_raise_for_status\n",
            "    response.raise_for_status()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/requests/models.py\", line 1026, in raise_for_status\n",
            "    raise HTTPError(http_error_msg, response=self)\n",
            "requests.exceptions.HTTPError: 401 Client Error: Unauthorized for url: https://huggingface.co/mistralai/Mistral-7B-v0.1/resolve/main/config.json\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py\", line 478, in cached_files\n",
            "    hf_hub_download(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\", line 1010, in hf_hub_download\n",
            "    return _hf_hub_download_to_cache_dir(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\", line 1117, in _hf_hub_download_to_cache_dir\n",
            "    _raise_on_head_call_error(head_call_error, force_download, local_files_only)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\", line 1658, in _raise_on_head_call_error\n",
            "    raise head_call_error\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\", line 1546, in _get_metadata_or_catch_error\n",
            "    metadata = get_hf_file_metadata(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\", line 1463, in get_hf_file_metadata\n",
            "    r = _request_wrapper(\n",
            "        ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\", line 286, in _request_wrapper\n",
            "    response = _request_wrapper(\n",
            "               ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\", line 310, in _request_wrapper\n",
            "    hf_raise_for_status(response)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_http.py\", line 482, in hf_raise_for_status\n",
            "    raise _format(HfHubHTTPError, str(e), response) from e\n",
            "huggingface_hub.errors.HfHubHTTPError: 401 Client Error: Unauthorized for url: https://huggingface.co/mistralai/Mistral-7B-v0.1/resolve/main/config.json (Request ID: Root=1-68c00103-07730158172a6b6c605624fd;2a123147-a302-4293-918f-aef887bee05c)\n",
            "\n",
            "Invalid credentials in Authorization header\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-3602496430.py\", line 70, in load_local_model\n",
            "    tokenizer = AutoTokenizer.from_pretrained(model_id, **tokenizer_kwargs)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/models/auto/tokenization_auto.py\", line 1078, in from_pretrained\n",
            "    config = AutoConfig.from_pretrained(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/models/auto/configuration_auto.py\", line 1288, in from_pretrained\n",
            "    config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)\n",
            "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/configuration_utils.py\", line 662, in get_config_dict\n",
            "    config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)\n",
            "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/configuration_utils.py\", line 721, in _get_config_dict\n",
            "    resolved_config_file = cached_file(\n",
            "                           ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py\", line 321, in cached_file\n",
            "    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py\", line 562, in cached_files\n",
            "    raise OSError(f\"There was a specific connection error when trying to load {path_or_repo_id}:\\n{e}\") from e\n",
            "OSError: There was a specific connection error when trying to load mistralai/Mistral-7B-v0.1:\n",
            "401 Client Error: Unauthorized for url: https://huggingface.co/mistralai/Mistral-7B-v0.1/resolve/main/config.json (Request ID: Root=1-68c00103-07730158172a6b6c605624fd;2a123147-a302-4293-918f-aef887bee05c)\n",
            "\n",
            "Invalid credentials in Authorization header\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error loading mistral-7b: There was a specific connection error when trying to load mistralai/Mistral-7B-v0.1:\n",
            "401 Client Error: Unauthorized for url: https://huggingface.co/mistralai/Mistral-7B-v0.1/resolve/main/config.json (Request ID: Root=1-68c00103-07730158172a6b6c605624fd;2a123147-a302-4293-918f-aef887bee05c)\n",
            "\n",
            "Invalid credentials in Authorization header\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating mistral-7b:   0%|          | 0/2 [00:00<?, ?it/s]WARNING:sentence_transformers.SentenceTransformer:No sentence-transformers model found with name sentence-transformers/all-mpnet-base-v2. Creating a new one with mean pooling.\n",
            "Evaluating mistral-7b:  50%|█████     | 1/2 [00:00<00:00,  1.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error in generation: There was a specific connection error when trying to load sentence-transformers/all-mpnet-base-v2:\n",
            "401 Client Error: Unauthorized for url: https://huggingface.co/sentence-transformers/all-mpnet-base-v2/resolve/main/config.json (Request ID: Root=1-68c00104-4065358167149fc07219070c;6a653424-000b-4b6b-8ab8-92e2d66074a9)\n",
            "\n",
            "Invalid credentials in Authorization header\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sentence_transformers.SentenceTransformer:No sentence-transformers model found with name sentence-transformers/all-mpnet-base-v2. Creating a new one with mean pooling.\n",
            "Evaluating mistral-7b: 100%|██████████| 2/2 [00:01<00:00,  1.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error in generation: There was a specific connection error when trying to load sentence-transformers/all-mpnet-base-v2:\n",
            "401 Client Error: Unauthorized for url: https://huggingface.co/sentence-transformers/all-mpnet-base-v2/resolve/main/config.json (Request ID: Root=1-68c00105-6c3875ce52b1a4a414c4d7ac;21ec8259-445c-406a-b3af-5509f051d3f2)\n",
            "\n",
            "Invalid credentials in Authorization header\n",
            "Evaluating mistral-7b on mimic_cxr dataset...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_http.py\", line 409, in hf_raise_for_status\n",
            "    response.raise_for_status()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/requests/models.py\", line 1026, in raise_for_status\n",
            "    raise HTTPError(http_error_msg, response=self)\n",
            "requests.exceptions.HTTPError: 401 Client Error: Unauthorized for url: https://huggingface.co/mistralai/Mistral-7B-v0.1/resolve/main/config.json\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py\", line 478, in cached_files\n",
            "    hf_hub_download(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\", line 1010, in hf_hub_download\n",
            "    return _hf_hub_download_to_cache_dir(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\", line 1117, in _hf_hub_download_to_cache_dir\n",
            "    _raise_on_head_call_error(head_call_error, force_download, local_files_only)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\", line 1658, in _raise_on_head_call_error\n",
            "    raise head_call_error\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\", line 1546, in _get_metadata_or_catch_error\n",
            "    metadata = get_hf_file_metadata(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\", line 1463, in get_hf_file_metadata\n",
            "    r = _request_wrapper(\n",
            "        ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\", line 286, in _request_wrapper\n",
            "    response = _request_wrapper(\n",
            "               ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\", line 310, in _request_wrapper\n",
            "    hf_raise_for_status(response)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_http.py\", line 482, in hf_raise_for_status\n",
            "    raise _format(HfHubHTTPError, str(e), response) from e\n",
            "huggingface_hub.errors.HfHubHTTPError: 401 Client Error: Unauthorized for url: https://huggingface.co/mistralai/Mistral-7B-v0.1/resolve/main/config.json (Request ID: Root=1-68c00105-0c3b042577a9060b78306cca;92065ee8-99c4-46fc-9a8b-11aff1590e6f)\n",
            "\n",
            "Invalid credentials in Authorization header\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-3602496430.py\", line 70, in load_local_model\n",
            "    tokenizer = AutoTokenizer.from_pretrained(model_id, **tokenizer_kwargs)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/models/auto/tokenization_auto.py\", line 1078, in from_pretrained\n",
            "    config = AutoConfig.from_pretrained(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/models/auto/configuration_auto.py\", line 1288, in from_pretrained\n",
            "    config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)\n",
            "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/configuration_utils.py\", line 662, in get_config_dict\n",
            "    config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)\n",
            "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/configuration_utils.py\", line 721, in _get_config_dict\n",
            "    resolved_config_file = cached_file(\n",
            "                           ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py\", line 321, in cached_file\n",
            "    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py\", line 562, in cached_files\n",
            "    raise OSError(f\"There was a specific connection error when trying to load {path_or_repo_id}:\\n{e}\") from e\n",
            "OSError: There was a specific connection error when trying to load mistralai/Mistral-7B-v0.1:\n",
            "401 Client Error: Unauthorized for url: https://huggingface.co/mistralai/Mistral-7B-v0.1/resolve/main/config.json (Request ID: Root=1-68c00105-0c3b042577a9060b78306cca;92065ee8-99c4-46fc-9a8b-11aff1590e6f)\n",
            "\n",
            "Invalid credentials in Authorization header\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error loading mistral-7b: There was a specific connection error when trying to load mistralai/Mistral-7B-v0.1:\n",
            "401 Client Error: Unauthorized for url: https://huggingface.co/mistralai/Mistral-7B-v0.1/resolve/main/config.json (Request ID: Root=1-68c00105-0c3b042577a9060b78306cca;92065ee8-99c4-46fc-9a8b-11aff1590e6f)\n",
            "\n",
            "Invalid credentials in Authorization header\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating mistral-7b:   0%|          | 0/2 [00:00<?, ?it/s]WARNING:sentence_transformers.SentenceTransformer:No sentence-transformers model found with name sentence-transformers/all-mpnet-base-v2. Creating a new one with mean pooling.\n",
            "Evaluating mistral-7b:  50%|█████     | 1/2 [00:01<00:01,  1.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error in generation: There was a specific connection error when trying to load sentence-transformers/all-mpnet-base-v2:\n",
            "401 Client Error: Unauthorized for url: https://huggingface.co/sentence-transformers/all-mpnet-base-v2/resolve/main/config.json (Request ID: Root=1-68c00107-0f3f90441fd6c2f714995137;4606fc06-be83-436f-91b1-df65d06fafd6)\n",
            "\n",
            "Invalid credentials in Authorization header\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sentence_transformers.SentenceTransformer:No sentence-transformers model found with name sentence-transformers/all-mpnet-base-v2. Creating a new one with mean pooling.\n",
            "Evaluating mistral-7b: 100%|██████████| 2/2 [00:01<00:00,  1.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error in generation: There was a specific connection error when trying to load sentence-transformers/all-mpnet-base-v2:\n",
            "401 Client Error: Unauthorized for url: https://huggingface.co/sentence-transformers/all-mpnet-base-v2/resolve/main/config.json (Request ID: Root=1-68c00107-5bb469b05f1bb7105ee35a2a;73f0742a-6dab-49d0-947f-f42e900c1e4c)\n",
            "\n",
            "Invalid credentials in Authorization header\n",
            "Created directory: model_evaluation_mistral-7b/charts\n",
            "Created directory: model_evaluation_mistral-7b/data\n",
            "Created directory: model_evaluation_mistral-7b/tables\n",
            "Created directory: model_evaluation_mistral-7b/dataset_analysis\n",
            "Created chart: model_evaluation_mistral-7b/charts/accuracy_bar_chart.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created chart: model_evaluation_mistral-7b/charts/hallucination_rate_bar_chart.png\n",
            "Created chart: model_evaluation_mistral-7b/charts/confidence_bar_chart.png\n",
            "Created chart: model_evaluation_mistral-7b/charts/radar_chart.png\n",
            "Created table: model_evaluation_mistral-7b/tables/comparison_table.html\n",
            "Created chart: model_evaluation_mistral-7b/charts/dataset_comparison_chart.png\n",
            "Created chart: model_evaluation_mistral-7b/charts/pubmedqa_radar_chart.png\n",
            "Created chart: model_evaluation_mistral-7b/charts/medqa_radar_chart.png\n",
            "Created chart: model_evaluation_mistral-7b/charts/mimic_cxr_radar_chart.png\n",
            "Exported 11 files to model_evaluation_mistral-7b/ directory structure\n",
            "Files created:\n",
            "  - model_evaluation_mistral-7b/data/mistral-7b_ui_export_data.json\n",
            "  - model_evaluation_mistral-7b/data/mistral-7b_comprehensive_results.json\n",
            "  - model_evaluation_mistral-7b/charts/accuracy_bar_chart.png\n",
            "  - model_evaluation_mistral-7b/charts/hallucination_rate_bar_chart.png\n",
            "  - model_evaluation_mistral-7b/charts/confidence_bar_chart.png\n",
            "  - model_evaluation_mistral-7b/charts/radar_chart.png\n",
            "  - model_evaluation_mistral-7b/tables/comparison_table.html\n",
            "  - model_evaluation_mistral-7b/charts/dataset_comparison_chart.png\n",
            "  - model_evaluation_mistral-7b/charts/pubmedqa_radar_chart.png\n",
            "  - model_evaluation_mistral-7b/charts/medqa_radar_chart.png\n",
            "  - model_evaluation_mistral-7b/charts/mimic_cxr_radar_chart.png\n",
            "Created ZIP archive: model_evaluation_mistral-7b.zip\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_05613842-a6a5-4df8-b251-2502f3323b90\", \"model_evaluation_mistral-7b.zip\", 540647)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "twD7IwpmxOOd"
      },
      "execution_count": 25,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "authorship_tag": "ABX9TyOYro9wNiSwk+jB3NUuN4YQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}